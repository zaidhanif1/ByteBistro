import { HF_HUB_URL } from "../config.js";
import { HARDCODED_MODEL_INFERENCE_MAPPING } from "../providers/consts.js";
import { EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS } from "../providers/hf-inference.js";
import { typedInclude } from "../utils/typedInclude.js";
export const inferenceProviderMappingCache = new Map();
export async function fetchInferenceProviderMappingForModel(modelId, accessToken, options) {
    let inferenceProviderMapping;
    if (inferenceProviderMappingCache.has(modelId)) {
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        inferenceProviderMapping = inferenceProviderMappingCache.get(modelId);
    }
    else {
        const resp = await (options?.fetch ?? fetch)(`${HF_HUB_URL}/api/models/${modelId}?expand[]=inferenceProviderMapping`, {
            headers: accessToken?.startsWith("hf_") ? { Authorization: `Bearer ${accessToken}` } : {},
        });
        if (resp.status === 404) {
            throw new Error(`Model ${modelId} does not exist`);
        }
        inferenceProviderMapping = await resp
            .json()
            .then((json) => json.inferenceProviderMapping)
            .catch(() => null);
        if (inferenceProviderMapping) {
            inferenceProviderMappingCache.set(modelId, inferenceProviderMapping);
        }
    }
    if (!inferenceProviderMapping) {
        throw new Error(`We have not been able to find inference provider information for model ${modelId}.`);
    }
    return inferenceProviderMapping;
}
export async function getInferenceProviderMapping(params, options) {
    if (HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId]) {
        return HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId];
    }
    const inferenceProviderMapping = await fetchInferenceProviderMappingForModel(params.modelId, params.accessToken, options);
    const providerMapping = inferenceProviderMapping[params.provider];
    if (providerMapping) {
        const equivalentTasks = params.provider === "hf-inference" && typedInclude(EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS, params.task)
            ? EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS
            : [params.task];
        if (!typedInclude(equivalentTasks, providerMapping.task)) {
            throw new Error(`Model ${params.modelId} is not supported for task ${params.task} and provider ${params.provider}. Supported task: ${providerMapping.task}.`);
        }
        if (providerMapping.status === "staging") {
            console.warn(`Model ${params.modelId} is in staging mode for provider ${params.provider}. Meant for test purposes only.`);
        }
        return { ...providerMapping, hfModelId: params.modelId };
    }
    return null;
}
export async function resolveProvider(provider, modelId, endpointUrl) {
    if (endpointUrl) {
        if (provider) {
            throw new Error("Specifying both endpointUrl and provider is not supported.");
        }
        /// Defaulting to hf-inference helpers / API
        return "hf-inference";
    }
    if (!provider) {
        console.log("Defaulting to 'auto' which will select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.");
        provider = "auto";
    }
    if (provider === "auto") {
        if (!modelId) {
            throw new Error("Specifying a model is required when provider is 'auto'");
        }
        const inferenceProviderMapping = await fetchInferenceProviderMappingForModel(modelId);
        provider = Object.keys(inferenceProviderMapping)[0];
    }
    if (!provider) {
        throw new Error(`No Inference Provider available for model ${modelId}.`);
    }
    return provider;
}
